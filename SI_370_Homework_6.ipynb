{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# SI 370 - Homework 6 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version 2023.11.15.1.CT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you'll apply your knowledge of classification to text analysis, specifically real and fake news. Your task is to predict whether a news article is real or fake using the available information.\n",
    "\n",
    "The dataset that you'll use can be downloaded from and is described at https://www.kaggle.com/datasets/clmentbisaillon/fake-and-real-news-dataset as well as the following references:\n",
    "\n",
    "Ahmed H, Traore I, Saad S. “Detecting opinion spams and fake news using text classification”, Journal of Security and Privacy, Volume 1, Issue 1, Wiley, January/February 2018.\n",
    "\n",
    "Ahmed H, Traore I, Saad S. (2017) “Detection of Online Fake News Using N-Gram Analysis and Machine Learning Techniques. In: Traore I., Woungang I., Awad A. (eds) Intelligent, Secure, and Dependable Systems in Distributed and Cloud Environments. ISDDC 2017. Lecture Notes in Computer Science, vol 10618. Springer, Cham (pp. 127-138).\n",
    "\n",
    "You will probably get the most informative information from the content of the articles as well as their titles.\n",
    "\n",
    "**IMPORTANT NOTE**: You _must_ remove the news agency names from the articles.  For example, if an article is from Reuters, you should remove the word \"Reuters\" from the article.  This is because the news agency name is a very strong indicator of whether an article is real or fake, and we want you to focus on the content of the article itself.  You can use the following code similar to the following to remove the news agency names:\n",
    "\n",
    "```python\n",
    "import re\n",
    "def remove_news_agency_name(text):\n",
    "    return re.sub(r\"Reuters|AP|New York Times|Washington Post|Business Insider|Atlantic|Fox News|National Review|Talking Points Memo|Buzzfeed News|Guardian|NPR|Vox|CNN|BBC|Bloomberg|Daily Mail\", \"\", text)\n",
    "```\n",
    "\n",
    "You have at your disposal several\n",
    "techniques that you can use to create features from text, including, word embedding, part-of-speech analysis (from SI 330), and so on.  You might want to use CountVectorizer and/or TfidfVectorizer from the\n",
    "sklearn.feature_extraction library, which are described below.\n",
    "\n",
    "You should pre-process your text using at least some of the steps outlined in lectures (e.g. normalizing to lowercase, splitting into words, etc.).\n",
    "\n",
    "The articles are provided in two different files: Fake.csv and True.csv.  We recommend that you create a dataframe with the contents of those files combined, including a new column that specifies whether the article is real or fake (note that you can use whatever coding you want for \"real\" vs. \"fake\", e.g. 1 and 0, \"real\" and \"fake\", \"false\" and \"true\" -- whatever works for you.\n",
    "\n",
    "You should split the resulting combined dataframe into training and testing datasets OR use cross-validation.  If you go the splitting-into-training-and-testing route, we recommend an 80-20 split (i.e. training gets 80% of the data; testing gets 20%) and use the testing dataset to report your accuracy score.  If you go the cross-validation route, we recommend using 5-fold cross-validation and use the mean accuracy score for your 5 folds when reporting your accuracy score.\n",
    "\n",
    "\n",
    "Much like the previous homework assignment, you'll want to try a variety of classifiers and possibly use an ensemble.  And, in a similar way to the previous homework assignment, your submission (to Canvas -- there is no requirement to submit this anywhere else, including Kaggle) should be based on a Jupyter notebook that you create.\n",
    "\n",
    "As as final challenge, we would like you to attempt to characterize each of the datasets in terms of their semantic content.  This might involve extracting the most commonly occurring words (possibly limiting that to specific parts of speech), examining the Named Entities, and extracting keywords by leveraging word embeddings.  Use your imagination, and remember there is no single \"correct\" answer.  For those of you looking to teach yourself something new, check out Latent Dirichilet Allocation (LDA) using the `gensim` library.  To get started with LDA, check out https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/ and https://radimrehurek.com/gensim/models/ldamodel.html.  You are not required to use LDA, but it is a powerful technique for extracting topics from text. \n",
    "\n",
    "Points will be allocated as follows:\n",
    "\n",
    "| Component | Points |\n",
    "|:---|:---|\n",
    "|1. Text pre-processing and feature extraction, including justification for your choices| 8 |\n",
    "|2. Use of at least three classifiers, not including VotingClassifier (if you use it) |  6  |\n",
    "|3. Accuracy (based on test dataset)| 75%: 1 , 80%: 2 , 90%: 3  |\n",
    "|4. Topic summarization | 3 |\n",
    "Note that you are welcome to use VotingClassifier to improve your accuracy, you just can't count it as one of the three classifiers for points in Component 2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following tutorial is from https://www.kaggle.com/adamschroeder/countvectorizer-tfidfvectorizer-predict-comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install sklearn-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install rake_nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "_cell_guid": "d185e5fb-ac9a-40a2-b563-d9aa1a77f94e",
    "_uuid": "1008fd2001c2b8485d2b4815813f90b722286c22"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import re\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk import Text\n",
    "from nltk.tokenize import regexp_tokenize\n",
    "from nltk.tokenize import word_tokenize  \n",
    "from nltk.tokenize import sent_tokenize \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from spacy.tokens import Doc\n",
    "from collections import Counter\n",
    "import spacy\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "from rake_nltk import Rake\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = pd.read_csv('Fake.csv')\n",
    "real = pd.read_csv('True.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>fake_or_real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 30, 2017</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 25, 2017</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
       "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
       "\n",
       "                                                text subject  \\\n",
       "0  Donald Trump just couldn t wish all Americans ...    News   \n",
       "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
       "2  On Friday, it was revealed that former Milwauk...    News   \n",
       "3  On Christmas day, Donald Trump announced that ...    News   \n",
       "4  Pope Francis used his annual Christmas Day mes...    News   \n",
       "\n",
       "                date fake_or_real  \n",
       "0  December 31, 2017         Fake  \n",
       "1  December 31, 2017         Fake  \n",
       "2  December 30, 2017         Fake  \n",
       "3  December 29, 2017         Fake  \n",
       "4  December 25, 2017         Fake  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake['fake_or_real'] = 'Fake'\n",
    "real['fake_or_real'] = 'Real'\n",
    "\n",
    "# combine the dataframes\n",
    "news_df = pd.concat([fake, real], ignore_index=True)\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_news_agency_name(text):\n",
    "    return re.sub(r\"Reuters|AP|New York Times|Washington Post|Business Insider|Atlantic|Fox News|National Review|Talking Points Memo|Buzzfeed News|Guardian|NPR|Vox|CNN|BBC|Bloomberg|Daily Mail\", \"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removes agency names and removes non-alphabetic characters and converts to lowercase\n",
    "news_df = news_df.assign(text=news_df.text.apply(remove_news_agency_name))\n",
    "news_df['text'] = news_df['text'].str.replace(\"[^a-zA-Z]\", \" \")\n",
    "news_df['text'] = news_df['text'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = news_df['text']\n",
    "y = news_df['fake_or_real']\n",
    "\n",
    "# Create a TfidfVectorizer object\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform X\n",
    "X = vectorizer.fit_transform(X)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression: 0.9810690423162584\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "clf1 = LogisticRegression()\n",
    "\n",
    "# Fit the model\n",
    "clf1.fit(X_train, y_train)\n",
    "\n",
    "# Print out the accuracy\n",
    "print(f\"Accuracy of Logistic Regression: {clf1.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest: 0.9792873051224944\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "clf2 = RandomForestClassifier()\n",
    "\n",
    "# Fit the model\n",
    "clf2.fit(X_train, y_train)\n",
    "\n",
    "# Print out the accuracy\n",
    "print(f\"Accuracy of Random Forest: {clf2.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Naive Bayes: 0.9326280623608018\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "clf3 = MultinomialNB()\n",
    "\n",
    "# Fit the model\n",
    "clf3.fit(X_train, y_train)\n",
    "\n",
    "# Print out the accuracy\n",
    "print(f\"Accuracy of Naive Bayes: {clf3.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM: 0.9891982182628062\n"
     ]
    }
   ],
   "source": [
    "#This took a really long time to run\n",
    "# SVM\n",
    "clf4 = svm.SVC()\n",
    "\n",
    "# Fit the model\n",
    "clf4.fit(X_train, y_train)\n",
    "\n",
    "# Print out the accuracy\n",
    "print(f\"Accuracy of SVM: {clf4.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Ensemble: 0.9837416481069042\n"
     ]
    }
   ],
   "source": [
    "# Define an ensemble classifier\n",
    "eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3), ('svm', clf4)], voting='hard')\n",
    "\n",
    "# Fit the model\n",
    "eclf.fit(X_train, y_train)\n",
    "\n",
    "# Print out the accuracy\n",
    "print(f\"Accuracy of Ensemble: {eclf.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Accuracy Results:\n",
    "* Accuracy of Logistic Regression: 0.9810690423162584\n",
    "* Accuracy of Random Forest: 0.9793986636971047\n",
    "* Accuracy of Naive Bayes: 0.9326280623608018\n",
    "* Accuracy of SVM: 0.9834075723830735"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize text\n",
    "news_df['tokenized_text'] = news_df['text'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to remove stopwords and punctuation\n",
    "def clean(tokens):\n",
    "    # Remove stopwords\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    # Remove punctuation\n",
    "    tokens = [''.join(c for c in w if c not in string.punctuation) for w in tokens]\n",
    "    # Remove empty strings caused by removing punctuations\n",
    "    tokens = [w for w in tokens if w]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df['cleaned_text'] = news_df['tokenized_text'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('said', 130206),\n",
       " ('trump', 128628),\n",
       " ('’', 70768),\n",
       " ('us', 63311),\n",
       " ('would', 54989),\n",
       " ('“', 54140),\n",
       " ('”', 53861),\n",
       " ('president', 52246),\n",
       " ('people', 41272),\n",
       " ('one', 35718)]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words = [word for sublist in news_df['cleaned_text'] for word in sublist]\n",
    "\n",
    "# Use Counter to find the most common words\n",
    "most_common_words = Counter(all_words).most_common(10)\n",
    "most_common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/michaelaianaki/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentiment analysis\n",
    "sent_analyzer = SentimentIntensityAnalyzer()\n",
    "def sentiment_scores(docx):\n",
    "    return sent_analyzer.polarity_scores(docx.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df['sentiment'] = news_df.apply(sentiment_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [donald, trump, wish, americans, happy, new, y...\n",
       "1        [house, intelligence, committee, chairman, dev...\n",
       "2        [friday, revealed, former, milwaukee, sheriff,...\n",
       "3        [christmas, day, donald, trump, announced, wou...\n",
       "4        [pope, francis, used, annual, christmas, day, ...\n",
       "                               ...                        \n",
       "44893    [brussels, nato, allies, tuesday, welcomed, pr...\n",
       "44894    [london, lexisnexis, provider, legal, regulato...\n",
       "44895    [minsk, shadow, disused, sovietera, factories,...\n",
       "44896    [moscow, vatican, secretary, state, cardinal, ...\n",
       "44897    [jakarta, indonesia, buy, 11, sukhoi, fighter,...\n",
       "Name: cleaned_text, Length: 44898, dtype: object"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df['cleaned_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(news_df['cleaned_text'])\n",
    "corpus = [dictionary.doc2bow(text) for text in news_df['cleaned_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaModel(corpus, num_topics=10, id2word=dictionary, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.026*\"said\" + 0.009*\"people\" + 0.009*\"police\" + 0.007*\"state\"')\n",
      "(1, '0.035*\"court\" + 0.017*\"law\" + 0.010*\"supreme\" + 0.009*\"rights\"')\n",
      "(2, '0.025*\"said\" + 0.013*\"us\" + 0.010*\"united\" + 0.009*\"north\"')\n",
      "(3, '0.015*\"women\" + 0.010*\"school\" + 0.008*\"facebook\" + 0.007*\"students\"')\n",
      "(4, '0.011*\"would\" + 0.008*\"percent\" + 0.008*\"said\" + 0.008*\"million\"')\n",
      "(5, '0.013*\"people\" + 0.007*\"like\" + 0.007*\"one\" + 0.006*\"obama\"')\n",
      "(6, '0.030*\"israel\" + 0.023*\"hurricane\" + 0.019*\"irma\" + 0.018*\"jerusalem\"')\n",
      "(7, '0.050*\"trump\" + 0.011*\"media\" + 0.010*\"donald\" + 0.009*\"news\"')\n",
      "(8, '0.011*\"said\" + 0.010*\"russian\" + 0.009*\"us\" + 0.009*\"russia\"')\n",
      "(9, '0.039*\"’\" + 0.031*\"trump\" + 0.030*\"said\" + 0.030*\"“\"')\n"
     ]
    }
   ],
   "source": [
    "topics = lda_model.print_topics(num_words=4)\n",
    "#prints topics and weight\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Word2Vec model\n",
    "#model = gensim.models.Word2Vec(news_df['cleaned_text'], window=5, min_count=1, workers=4, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_code_all_hidden": true,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
